{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ccea1e-f04d-4d19-94c1-a09e38a61433",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sksurv.datasets import load_whas500\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29c9a2a-5455-485b-ba46-149de1c256ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_whas500()\n",
    "X = X.astype(float)\n",
    "# Combining features and events is easier to work with for now\n",
    "combined = pd.concat([X, pd.DataFrame(y)], axis=1)\n",
    "combined['lenfol'] = combined['lenfol'].astype(int)\n",
    "TARGET_COLUMNS = ['fstat', 'lenfol']\n",
    "\n",
    "\n",
    "\n",
    "right_censored = np.array([el[0] for el in y])\n",
    "event_times = np.array([el[1] for el in y]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ebe64-4ae5-4aa8-90ed-d1c17768fd8a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Constructing the components\n",
    "In order to solve equation 8we need to filter and group the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9f0ed0-eeb1-4862-8fb3-6634bfdce6a7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## $D_t$\n",
    "We need to group the records on event time, ignore the right-censored records\n",
    "\n",
    "Then we get $D_t$ for every $t$ from $t=1$ to $T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ecec6bd-e7bd-4e97-b3e1-02ffacf0a002",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">afb</th>\n",
       "      <th colspan=\"2\" halign=\"left\">age</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sho</th>\n",
       "      <th colspan=\"8\" halign=\"left\">sysbp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lenfol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.00</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.00</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>132.333333</td>\n",
       "      <td>18.610033</td>\n",
       "      <td>115.0</td>\n",
       "      <td>122.50</td>\n",
       "      <td>130.0</td>\n",
       "      <td>141.00</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.00</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.00</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>22.627417</td>\n",
       "      <td>179.0</td>\n",
       "      <td>187.00</td>\n",
       "      <td>195.0</td>\n",
       "      <td>203.00</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>141.500000</td>\n",
       "      <td>34.648232</td>\n",
       "      <td>117.0</td>\n",
       "      <td>129.25</td>\n",
       "      <td>141.5</td>\n",
       "      <td>153.75</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         afb                                      age             ...  sho  \\\n",
       "       count mean  std  min  25%  50%  75%  max count       mean  ...  75%   \n",
       "lenfol                                                            ...        \n",
       "368      1.0  0.0  NaN  0.0  0.0  0.0  0.0  0.0   1.0  46.000000  ...  0.0   \n",
       "371      3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   3.0  73.333333  ...  0.0   \n",
       "373      1.0  0.0  NaN  0.0  0.0  0.0  0.0  0.0   1.0  65.000000  ...  0.0   \n",
       "376      2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   2.0  60.000000  ...  0.0   \n",
       "386      2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   2.0  55.500000  ...  0.0   \n",
       "\n",
       "            sysbp                                                              \n",
       "        max count        mean        std    min     25%    50%     75%    max  \n",
       "lenfol                                                                         \n",
       "368     0.0   1.0  149.000000        NaN  149.0  149.00  149.0  149.00  149.0  \n",
       "371     0.0   3.0  132.333333  18.610033  115.0  122.50  130.0  141.00  152.0  \n",
       "373     0.0   1.0  164.000000        NaN  164.0  164.00  164.0  164.00  164.0  \n",
       "376     0.0   2.0  195.000000  22.627417  179.0  187.00  195.0  203.00  211.0  \n",
       "386     0.0   2.0  141.500000  34.648232  117.0  129.25  141.5  153.75  166.0  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First ignore all right-censored records\n",
    "dt = combined[~combined['fstat']]\n",
    "\n",
    "# We don't need the censor column anymore\n",
    "dt = dt.drop(['fstat'], axis=1)\n",
    "\n",
    "# Group on event time\n",
    "dt = dt.groupby('lenfol')\n",
    "\n",
    "dt.describe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cde6a8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## $R_t$\n",
    "$R_t$ denotes the set of samples at risk of the event at time $t$. This includes samples with an event at time t, the samples with an event later than time t, and right-censored samples.\n",
    "\n",
    "*I __think__ that I can treat right-censored samples the same as regular samples for this set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e49862",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rt = combined\n",
    "\n",
    "# I will create a bucket per unique lenfol and create a new dataframe per bucket with all samples at risk at that time\n",
    "unique_times = rt['lenfol'].unique()\n",
    "\n",
    "num_unique_times = len(unique_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b84ff7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.arange(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a12ca6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def group_samples_at_risk(event_times: np.array):\n",
    "    \"\"\"\n",
    "    Groups the indices of samples on whether they are at risk at a certain time.\n",
    "    \n",
    "    A sample is at risk at a certain time when its event time is greater or equal that time.\n",
    "    \"\"\"\n",
    "    unique_times = np.unique(event_times)\n",
    "    \n",
    "    grouped = {}\n",
    "    \n",
    "    for t in unique_times:\n",
    "        grouped[t] = np.argwhere(event_times>= t)\n",
    "    \n",
    "    return grouped\n",
    "\n",
    "Rt = group_samples_at_risk(event_times)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d80d8b-3758-4e6e-aac8-1d55e5b07d36",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## $\\sum \\limits_{t=1}^{T} \\sum \\limits_{n \\in D_t} \\mathbf{x}_{nk}$\n",
    "\n",
    "$D_t$ is the list of indices with an observed event at time $t$.\n",
    "\n",
    "This part seems to be constant throughout the optimization?\n",
    "\n",
    "I think this is just a big fat sum of all the patients' covariants. It will stay constant per institution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4cebf30-02e7-4446-9428-27ca83f5cb24",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.800000e+01, 3.492300e+04, 1.100000e+01, 1.330689e+04,\n",
       "       1.550000e+02, 3.750000e+02, 3.913300e+04, 2.000000e+02,\n",
       "       4.350900e+04, 3.058000e+03, 1.710000e+02, 1.530000e+02,\n",
       "       2.200000e+01, 7.235200e+04])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariates_sum = combined.drop(TARGET_COLUMNS, axis=1).values.sum(axis=0)\n",
    "\n",
    "covariates_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f3b6248",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,  83.,   0., ...,   0.,   0., 152.],\n",
       "       [  0.,  49.,   0., ...,   1.,   0., 120.],\n",
       "       [  0.,  70.,   0., ...,   1.,   0., 147.],\n",
       "       ...,\n",
       "       [  1.,  57.,   0., ...,   0.,   0., 120.],\n",
       "       [  0.,  67.,   0., ...,   1.,   0., 112.],\n",
       "       [  0.,  98.,   0., ...,   1.,   0., 160.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Covariates\n",
    "X.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87705ee-c95f-48a3-ade6-4ce66d9c8e6e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Local update\n",
    "\n",
    "$ \\beta_k^{(p)} = \\bigg[ \\rho \\sum \\limits_{n=1}^{N} \\mathbf{x}_{nk}\\mathbf{x}_{nk}^T\\bigg]^{-1} \\cdot \\bigg[\\sum \\limits_{n=1}^N  (\\rho z_{nk}^{(p-1)} - \\gamma_{nk}^{p-1}) \\mathbf{x}_{nk} + \\sum \\limits_{t=1}^T \\sum \\limits_{n \\in D_t} \\mathbf{x}_{nk}\\bigg] $\n",
    "\n",
    "According to the paper, $\\mathbf{\\beta}$ will not be returned but $\\sigma$, which is computed as follows:\n",
    "$\\sigma_{nk} = \\mathbf{\\beta}_k^T \\mathbf{x}_{nk}$ where $k=1,...,K$\n",
    "\n",
    "### Performance optimization\n",
    "There are two parts to this computation that seem to be constant over iterations:\n",
    "1. $\\rho \\sum \\limits_{n=1}^{N} \\mathbf{x}_{nk}\\mathbf{x}_{nk}^T$\n",
    "2. $\\sum \\limits_{t=1}^T \\sum \\limits_{n \\in D_t} \\mathbf{x}_{nk}$\n",
    "\n",
    "Number 2. is also the part where we need to apply the scalar product protocol. We need this because (TODO: verify) we need to filter out right-censored samples.\n",
    "\n",
    "I think we can rewrite number 2. to:\n",
    "\n",
    "$\\sum \\limits_{n \\in E} \\mathbf{x}_{nk}$\n",
    "\n",
    "Where $E$ is the collection of samples that are NOT right-censored.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2d53fe3-ef61-4dca-958a-0c5428255bc2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Local update\n",
    "RHO = 0.25\n",
    "\n",
    "# Parts that stay constant over iterations\n",
    "# Square all covariates and sum them together\n",
    "# The formula says for every patient, x needs to be multiplied by itself.\n",
    "# Squaring all covariates with themselves comes down to the same thing since x_nk is supposed to\n",
    "# be one-dimensional\n",
    "multiplied_covariates = (X* X.transpose()).sum(axis=0)\n",
    "covariates_summed = combined.drop(TARGET_COLUMNS, axis=1).values.sum(axis=0)\n",
    "\n",
    "def sum_covariates(covariates: np.array):\n",
    "    return np.sum(covariates, axis=0)\n",
    "    \n",
    "def multiply_covariates(covariates: np.array):\n",
    "    return np.square(covariates).sum()\n",
    "\n",
    "def elementwise_multiply_sum(one_dim: np.array, two_dim: np.array):\n",
    "    \"\"\"\n",
    "    Every element in one_dim does elementwise multiplication with its corresponding row in two_dim.\n",
    "    \n",
    "    All rows of the result will be summed together vertically.\n",
    "    \"\"\"\n",
    "    multiplied = np.zeros(two_dim.shape)\n",
    "    for i in range(one_dim.shape[0]):\n",
    "        multiplied[i] = one_dim[i] * two_dim[i]\n",
    "        \n",
    "    return multiplied.sum(axis=0)\n",
    "    \n",
    "    \n",
    "\n",
    "def compute_beta(covariates:np.array, z:np.array, gamma:np.array, rho,\n",
    "                 multiplied_covariates, covariates_sum):\n",
    "    \n",
    "    first_component = 1/(rho * multiplied_covariates)\n",
    "    \n",
    "    pz = rho * z\n",
    "    \n",
    "    second_component = elementwise_multiply_sum(pz - gamma, covariates) + covariates_sum    \n",
    "    \n",
    "    return second_component/ first_component\n",
    "\n",
    "def compute_sigma(beta, covariates):\n",
    "    return np.matmul(covariates, beta)\n",
    "\n",
    "def local_update(covariates:np.array, z:np.array, gamma:np.array, rho,\n",
    "                 multiplied_covariates, covariates_sum):\n",
    "    \n",
    "    beta = compute_beta(covariates, z, gamma, rho, multiplied_covariates, covariates_sum)\n",
    "    \n",
    "    return compute_sigma(beta, covariates)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d8a0b4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95eab355",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_sum_covariates_returns_one_dim_array():\n",
    "    num_patients = 2\n",
    "    num_features = 2\n",
    "    \n",
    "    covariates = np.arange(num_patients * num_features).reshape((num_patients, num_features))\n",
    "    \n",
    "    result = sum_covariates(covariates)\n",
    "    assert result.shape == (num_features, ), f'Result is not one dimensional but shape {result.shape}'\n",
    "\n",
    "def test_multiply_covariates_returns_scalar():\n",
    "    num_patients = 2\n",
    "    num_features = 2\n",
    "    \n",
    "    covariates = np.arange(num_patients * num_features).reshape((num_patients, num_features))\n",
    "    \n",
    "    result = multiply_covariates(covariates)\n",
    "    assert np.isscalar(result) , f'Result is not scalar but shape {result.shape}'\n",
    "\n",
    "def test_elementwise_multiply_sum():\n",
    "    two_dim = np.array([[1,2], [3,4], [5,6]])\n",
    "    one_dim = np.array([1,2,3])\n",
    "    \n",
    "    result = elementwise_multiply_sum(one_dim, two_dim)\n",
    "    \n",
    "    assert result.shape == (two_dim.shape[1], ), f'Result shape is not same as number of columns in two_dim ({two_dim.shape[1]}) but {result.shape}'\n",
    "    \n",
    "    np.testing.assert_array_equal(result, np.array([22, 28]))\n",
    "    \n",
    "    \n",
    "def test_local_update():\n",
    "    num_patients = 3\n",
    "    num_features = 2\n",
    "    \n",
    "    rho=1\n",
    "    covariates = np.arange(num_patients*num_features).reshape((num_patients, num_features))\n",
    "    z = np.arange(num_patients)\n",
    "    gamma = np.arange(num_patients)\n",
    "    multiplied_cov = multiply_covariates(covariates)\n",
    "    summed_cov = sum_covariates(covariates)\n",
    "    \n",
    "    sigma = local_update(covariates, z, gamma, rho, multiplied_cov, summed_cov)\n",
    "    \n",
    "    assert sigma.shape == (num_patients, ), f'Updated value is not an array of shape {(num_features, )} but of shape: {updated}'\n",
    "\n",
    "test_sum_covariates_returns_one_dim_array()\n",
    "test_multiply_covariates_returns_scalar()\n",
    "test_elementwise_multiply_sum()\n",
    "test_local_update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee47d801",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Server update\n",
    "- Server computes:\n",
    "    - $\\overline{\\sigma}_n^{(p)} = \\sum \\limits_{k=1}^K \\sigma_{nk}^{(p)}/K $\n",
    "    - $\\overline{\\gamma}_{n}^{(p)} = \\sum \\limits_{k=1}^K \\gamma_{nk}^{(p)}/K $\n",
    "- Server computes $\\overline{z}^{(p)}$ by applying Newton-Raphson to:\n",
    "$ \\sum_{t=1}^T \\left[d_t log \\sum \\limits_{j \\in R_t} exp(K \\overline{z}_j) \\right] + K \\rho \\sum \\limits_{n=1}^N \\left[ \\frac{\\overline{z}_n^2}{2} - \n",
    "\\left( \\overline{\\sigma}_n^{(p)} + \\frac{\\overline{\\gamma}_n^{(p-1)}}{\\rho} \\right) \\overline{z}_n \\right]    $\n",
    "\n",
    "### Person-level auxiliary variables\n",
    "For the update the server makes use of the auxiliary variables $\\overline{\\sigma}$ and $\\overline{\\gamma}$. The elements of these vectors have a one-on-one relationship with the patients.\n",
    "\n",
    "Moreover, the server tries to find a variable $\\overline{z}$ which not only has a one-on-one relationship with the patients, but also needs to be grouped based on patients' event times.\n",
    "\n",
    "### Optimization method\n",
    "In order to get to a working end result I will skip the step of implementing the gradient and the Hessian. I will use the default method from `scipy.optimize.minimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78b23d8c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "K = 1 #Number of institutions\n",
    "dt = num_unique_times # Number of unique event times\n",
    "\n",
    "def L_z_parametrized(z: np.array, K: int, gamma:np.array, sigma, rho, samples_at_risk):\n",
    "    \n",
    "    dt = len(Rt)\n",
    "    \n",
    "    component1 = L_z_component1(z, samples_at_risk, dt)\n",
    "    component2 = L_z_component2(z, K, sigma,gamma, rho)\n",
    "    \n",
    "    return component1 + component2\n",
    "        \n",
    "def L_z_component1(z, samples_at_risk, unique_event_times):\n",
    "    result = 0\n",
    "    for t, group in samples_at_risk.items():\n",
    "        z_at_risk = z[group]\n",
    "        result += dt * (K * np.exp(z_at_risk)).sum()\n",
    "    \n",
    "    return result\n",
    "        \n",
    "def L_z_component2(z, K, sigma, gamma, rho):\n",
    "    element_wise = np.square(z)/2 - sigma + (gamma/rho) * z\n",
    "    return K * rho * element_wise.sum()\n",
    "    \n",
    "\n",
    "# Test if the output type is as expected (should be a scalar)\n",
    "\n",
    "def test_lz_outputs_scalar():\n",
    "    num_patients, num_features = 3, 2\n",
    "    num_parties = 1\n",
    "    samples_at_risk = {1: [0], 2: [1]}\n",
    "    \n",
    "    z = np.arange(num_patients)\n",
    "    gamma = z\n",
    "    sigma = z\n",
    "    rho = 2\n",
    "    \n",
    "    result = L_z_parametrized(z, num_parties, gamma, sigma, rho, samples_at_risk)\n",
    "    \n",
    "    assert np.isscalar(result)\n",
    "    \n",
    "test_lz_outputs_scalar()\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f3d61",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TODO: Implement derivatives\n",
    "As mentioned before, I'm skipping the implementaiton of the first- and second order partial derivatives for now. I will try to work with the default option of scipy that works without derivatives.\n",
    "Later on I will see if the computation can be sped up by using newton-raphson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8dea7c83",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 40.43530755237292\n",
       " hess_inv: array([[ 0.0988872 , -0.00172494],\n",
       "       [-0.00172494,  0.10940803]])\n",
       "      jac: array([8.10623169e-06, 4.76837158e-06])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 63\n",
       "      nit: 18\n",
       "     njev: 21\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([-3.91971792, -4.02566807])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def compute_z(num_parties, gamma, sigma, rho, samples_at_risk, z_start):\n",
    "    L_z = lambda z: L_z_parametrized(z, num_parties, gamma, sigma, rho, samples_at_risk)\n",
    "    \n",
    "    minimum = minimize(L_z, z_start)\n",
    "    \n",
    "    return minimum.x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40390d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Risks\n",
    "### Differential privacy-ish\n",
    "If the difference between $D_t$ and $D_{t+1}$, and similarly, the difference between $R_t$ and $R_{t+1}$ is too small, there is a great risk of data leakage. This needs to be addressed.\n",
    "\n",
    "### \"Gradient\" leakage\n",
    "The central server computes a variable $\\boldsymbol{\\overline{z}}$ which is a vector where every element corresponds to an individual patient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a86be5a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Next steps\n",
    "The next step is to put the puzzle pieces together into some kind of datanode and central node entities.\n",
    "\n",
    "I think it is best if I start to move to regular python modules now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
