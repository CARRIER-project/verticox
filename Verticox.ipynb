{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ccea1e-f04d-4d19-94c1-a09e38a61433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sksurv.datasets import load_whas500\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29c9a2a-5455-485b-ba46-149de1c256ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_whas500()\n",
    "X = X.astype(float)\n",
    "# Combining features and events is easier to work with for now\n",
    "combined = pd.concat([X, pd.DataFrame(y)], axis=1)\n",
    "combined['lenfol'] = combined['lenfol'].astype(int)\n",
    "TARGET_COLUMNS = ['fstat', 'lenfol']\n",
    "\n",
    "\n",
    "\n",
    "right_censored = np.array([el[0] for el in y])\n",
    "event_times = np.array([el[1] for el in y]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ebe64-4ae5-4aa8-90ed-d1c17768fd8a",
   "metadata": {},
   "source": [
    "# Constructing the components\n",
    "In order to solve equation 8we need to filter and group the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9f0ed0-eeb1-4862-8fb3-6634bfdce6a7",
   "metadata": {},
   "source": [
    "## $D_t$\n",
    "We need to group the records on event time, ignore the right-censored records\n",
    "\n",
    "Then we get $D_t$ for every $t$ from $t=1$ to $T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ecec6bd-e7bd-4e97-b3e1-02ffacf0a002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">afb</th>\n",
       "      <th colspan=\"2\" halign=\"left\">age</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sho</th>\n",
       "      <th colspan=\"8\" halign=\"left\">sysbp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lenfol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.00</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.00</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>132.333333</td>\n",
       "      <td>18.610033</td>\n",
       "      <td>115.0</td>\n",
       "      <td>122.50</td>\n",
       "      <td>130.0</td>\n",
       "      <td>141.00</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.00</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.00</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>22.627417</td>\n",
       "      <td>179.0</td>\n",
       "      <td>187.00</td>\n",
       "      <td>195.0</td>\n",
       "      <td>203.00</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>141.500000</td>\n",
       "      <td>34.648232</td>\n",
       "      <td>117.0</td>\n",
       "      <td>129.25</td>\n",
       "      <td>141.5</td>\n",
       "      <td>153.75</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         afb                                      age             ...  sho  \\\n",
       "       count mean  std  min  25%  50%  75%  max count       mean  ...  75%   \n",
       "lenfol                                                            ...        \n",
       "368      1.0  0.0  NaN  0.0  0.0  0.0  0.0  0.0   1.0  46.000000  ...  0.0   \n",
       "371      3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   3.0  73.333333  ...  0.0   \n",
       "373      1.0  0.0  NaN  0.0  0.0  0.0  0.0  0.0   1.0  65.000000  ...  0.0   \n",
       "376      2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   2.0  60.000000  ...  0.0   \n",
       "386      2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   2.0  55.500000  ...  0.0   \n",
       "\n",
       "            sysbp                                                              \n",
       "        max count        mean        std    min     25%    50%     75%    max  \n",
       "lenfol                                                                         \n",
       "368     0.0   1.0  149.000000        NaN  149.0  149.00  149.0  149.00  149.0  \n",
       "371     0.0   3.0  132.333333  18.610033  115.0  122.50  130.0  141.00  152.0  \n",
       "373     0.0   1.0  164.000000        NaN  164.0  164.00  164.0  164.00  164.0  \n",
       "376     0.0   2.0  195.000000  22.627417  179.0  187.00  195.0  203.00  211.0  \n",
       "386     0.0   2.0  141.500000  34.648232  117.0  129.25  141.5  153.75  166.0  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First ignore all right-censored records\n",
    "dt = combined[~combined['fstat']]\n",
    "\n",
    "# We don't need the censor column anymore\n",
    "dt = dt.drop(['fstat'], axis=1)\n",
    "\n",
    "# Group on event time\n",
    "dt = dt.groupby('lenfol')\n",
    "\n",
    "dt.describe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cde6a8",
   "metadata": {},
   "source": [
    "## $R_t$\n",
    "$R_t$ denotes the set of samples at risk of the event at time $t$. This includes samples with an event at time t, the samples with an event later than time t, and right-censored samples.\n",
    "\n",
    "*I __think__ that I can treat right-censored samples the same as regular samples for this set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e49862",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = combined\n",
    "\n",
    "# I will create a bucket per unique lenfol and create a new dataframe per bucket with all samples at risk at that time\n",
    "unique_times = rt['lenfol'].unique()\n",
    "\n",
    "num_unique_times = len(unique_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b84ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.arange(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a12ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_samples_at_risk(event_times: np.array):\n",
    "    \"\"\"\n",
    "    Groups the indices of samples on whether they are at risk at a certain time.\n",
    "    \n",
    "    A sample is at risk at a certain time when its event time is greater or equal that time.\n",
    "    \"\"\"\n",
    "    unique_times = np.unique(event_times)\n",
    "    \n",
    "    grouped = {}\n",
    "    \n",
    "    for t in unique_times:\n",
    "        grouped[t] = np.argwhere(event_times>= t)\n",
    "    \n",
    "    return grouped\n",
    "\n",
    "Rt = group_samples_at_risk(event_times)\n",
    "\n",
    "\n",
    "def test_group_samples_at_risk_numbers_descend():\n",
    "    # Testing if the resulting list descends in numbers\n",
    "    previous_length = len(event_times) + 1\n",
    "\n",
    "    for t in sorted(Rt.keys()):\n",
    "        length = len(Rt[t])\n",
    "\n",
    "        assert length < previous_length\n",
    "\n",
    "        previous_length = length\n",
    "        \n",
    "test_group_samples_at_risk_numbers_descend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d80d8b-3758-4e6e-aac8-1d55e5b07d36",
   "metadata": {},
   "source": [
    "## $\\sum \\limits_{t=1}^{T} \\sum \\limits_{n \\in D_t} \\mathbf{x}_{nk}$\n",
    "\n",
    "$D_t$ is the list of indices with an observed event at time $t$.\n",
    "\n",
    "This part seems to be constant throughout the optimization?\n",
    "\n",
    "I think this is just a big fat sum of all the patients' covariants. It will stay constant per institution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4cebf30-02e7-4446-9428-27ca83f5cb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.800000e+01, 3.492300e+04, 1.100000e+01, 1.330689e+04,\n",
       "       1.550000e+02, 3.750000e+02, 3.913300e+04, 2.000000e+02,\n",
       "       4.350900e+04, 3.058000e+03, 1.710000e+02, 1.530000e+02,\n",
       "       2.200000e+01, 7.235200e+04])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariates_sum = combined.drop(TARGET_COLUMNS, axis=1).values.sum(axis=0)\n",
    "\n",
    "covariates_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f3b6248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,  83.,   0., ...,   0.,   0., 152.],\n",
       "       [  0.,  49.,   0., ...,   1.,   0., 120.],\n",
       "       [  0.,  70.,   0., ...,   1.,   0., 147.],\n",
       "       ...,\n",
       "       [  1.,  57.,   0., ...,   0.,   0., 120.],\n",
       "       [  0.,  67.,   0., ...,   1.,   0., 112.],\n",
       "       [  0.,  98.,   0., ...,   1.,   0., 160.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Covariates\n",
    "X.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87705ee-c95f-48a3-ade6-4ce66d9c8e6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Local update\n",
    "\n",
    "$ \\beta_k^{(p)} = \\bigg[ \\rho \\sum \\limits_{n=1}^{N} \\mathbf{x}_{nk}\\mathbf{x}_{nk}^T\\bigg]^{-1} \\cdot \\bigg[\\sum \\limits_{n=1}^N  (\\rho z_{nk}^{(p-1)} - \\gamma_{nk}^{p-1}) \\mathbf{x}_{nk} + \\sum \\limits_{t=1}^T \\sum \\limits_{n \\in D_t} \\mathbf{x}_{nk}\\bigg] $\n",
    "\n",
    "There are two parts to this computation that seem to be constant over iterations:\n",
    "1. $\\rho \\sum \\limits_{n=1}^{N} \\mathbf{x}_{nk}\\mathbf{x}_{nk}^T$\n",
    "2. $\\sum \\limits_{t=1}^T \\sum \\limits_{n \\in D_t} \\mathbf{x}_{nk}$\n",
    "\n",
    "Number 2. is also the part where we need to apply the scalar product protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2d53fe3-ef61-4dca-958a-0c5428255bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariates: [[0 1]\n",
      " [2 3]]\n",
      "Result: 14\n",
      "(3, 2)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Result shape is not same as number of columns in two_dim but (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m test_sum_covariates_returns_one_dim_array()\n\u001b[1;32m     90\u001b[0m test_multiply_covariates_returns_scalar()\n\u001b[0;32m---> 91\u001b[0m \u001b[43mtest_elementwise_multiply_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m test_local_update()\n\u001b[1;32m     93\u001b[0m np\u001b[38;5;241m.\u001b[39marange()\n",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36mtest_elementwise_multiply_sum\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(two_dim\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     67\u001b[0m result \u001b[38;5;241m=\u001b[39m elemententwise_multiply_sum(one_dim, two_dim)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m result\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m two_dim\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResult shape is not same as number of columns in two_dim but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m22\u001b[39m, \u001b[38;5;241m28\u001b[39m])\n",
      "\u001b[0;31mAssertionError\u001b[0m: Result shape is not same as number of columns in two_dim but (2,)"
     ]
    }
   ],
   "source": [
    "# Local update\n",
    "RHO = 0.25\n",
    "\n",
    "# Parts that stay constant over iterations\n",
    "# Square all covariates and sum them together\n",
    "# The formula says for every patient, x needs to be multiplied by itself.\n",
    "# Squaring all covariates with themselves comes down to the same thing since x_nk is supposed to\n",
    "# be one-dimensional\n",
    "multiplied_covariates = (X* X.transpose()).sum(axis=0)\n",
    "covariates_summed = combined.drop(TARGET_COLUMNS, axis=1).values.sum(axis=0)\n",
    "\n",
    "def sum_covariates(covariates: np.array):\n",
    "    return np.sum(covariates, axis=0)\n",
    "    \n",
    "def multiply_covariates(covariates: np.array):\n",
    "    return np.square(covariates).sum()\n",
    "\n",
    "def elemententwise_multiply_sum(one_dim: np.array, two_dim: np.array):\n",
    "    \"\"\"\n",
    "    Every element in one_dim does elementwise multiplication with its corresponding row in two_dim.\n",
    "    \n",
    "    All rows of the result will be summed together vertically.\n",
    "    \"\"\"\n",
    "    multiplied = np.zeros(two_dim.shape)\n",
    "    for i in range(one_dim.shape[0]):\n",
    "        multiplied[i] = one_dim[i] * two_dim[i]\n",
    "        \n",
    "    return multiplied.sum(axis=0)\n",
    "    \n",
    "    \n",
    "\n",
    "def local_update(covariates:np.array, z:np.array, gamma:np.array, rho,\n",
    "                 multiplied_covariates, covariates_sum):\n",
    "    \n",
    "    first_component = 1/(rho * multiplied_covariates)\n",
    "    \n",
    "    pz = rho * z\n",
    "    \n",
    "    second_component = np.matmul(pz - gamma, covariates) + covariates_sum    \n",
    "    \n",
    "    return first_component * second_component\n",
    "\n",
    "def test_sum_covariates_returns_one_dim_array():\n",
    "    num_patients = 2\n",
    "    num_features = 2\n",
    "    \n",
    "    covariates = np.arange(num_patients * num_features).reshape((num_patients, num_features))\n",
    "    \n",
    "    result = sum_covariates(covariates)\n",
    "    assert result.shape == (num_features, ), f'Result is not one dimensional but shape {result.shape}'\n",
    "\n",
    "def test_multiply_covariates_returns_scalar():\n",
    "    num_patients = 2\n",
    "    num_features = 2\n",
    "    \n",
    "    covariates = np.arange(num_patients * num_features).reshape((num_patients, num_features))\n",
    "    \n",
    "    print(f'Covariates: {covariates}')\n",
    "    result = multiply_covariates(covariates)\n",
    "    print(f'Result: {result}')\n",
    "    assert np.isscalar(result) , f'Result is not scalar but shape {result.shape}'\n",
    "\n",
    "def test_elementwise_multiply_sum():\n",
    "    two_dim = np.array([[1,2], [3,4], [5,6]])\n",
    "    one_dim = np.array([1,2,3])\n",
    "    print(two_dim.shape)\n",
    "    result = elemententwise_multiply_sum(one_dim, two_dim)\n",
    "    \n",
    "    assert result.shape == two_dim.shape[1], f'Result shape is not same as number of columns in two_dim but {result.shape}'\n",
    "    \n",
    "    assert result == np.array([22, 28])\n",
    "    \n",
    "    \n",
    "def test_local_update():\n",
    "    num_patients = 3\n",
    "    num_features = 2\n",
    "    \n",
    "    rho=1\n",
    "    covariates = np.arange(num_patients*num_features).reshape((num_patients, num_features))\n",
    "    z = np.arange(num_patients)\n",
    "    gamma = np.arange(num_patients)\n",
    "    multiplied_cov = multiply_covariates(covariates)\n",
    "    summed_cov = sum_covariates(covariates)\n",
    "    \n",
    "    updated = local_update(covariates, z, gamma, rho, multiplied_cov, summed_cov)\n",
    "    \n",
    "    assert np.isscalar(updated.shape), f'Updated value is not scalar but value: {updated}'\n",
    "\n",
    "test_sum_covariates_returns_one_dim_array()\n",
    "test_multiply_covariates_returns_scalar()\n",
    "test_elementwise_multiply_sum()\n",
    "test_local_update()\n",
    "np.arange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ac849e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44678.3176510601"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient1 = X.values[0]\n",
    "\n",
    "np.matmul(patient1, patient1.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee47d801",
   "metadata": {},
   "source": [
    "## Server update\n",
    "- Server computes:\n",
    "    - $\\overline{\\sigma}_n^{(p)} = \\sum \\limits_{k=1}^K \\sigma_{nk}^{(p)}/K $\n",
    "    - $\\overline{\\gamma}_{n}^{(p)} = \\sum \\limits_{k=1}^K \\gamma_{nk}^{(p)}/K $\n",
    "- Server computes $\\overline{z}^{(p)}$ by applying Newton-Raphson to:\n",
    "$ \\sum_{t=1}^T \\left[d_t log \\sum \\limits_{j \\in R_t} exp(K \\overline{z}_j) \\right] + K \\rho \\sum \\limits_{n=1}^N \\left[ \\frac{\\overline{z}_n^2}{2} - \n",
    "\\left( \\overline{\\sigma}_n^{(p)} + \\frac{\\overline{\\gamma}_n^{(p-1)}}{\\rho} \\right) \\overline{z}_n \\right]    $\n",
    "\n",
    "### Person-level auxiliary variables\n",
    "For the update the server makes use of the auxiliary variables $\\overline{\\sigma}$ and $\\overline{\\gamma}$. The elements of these vectors have a one-on-one relationship with the patients.\n",
    "\n",
    "Moreover, the server tries to find a variable $\\overline{z}$ which not only has a one-on-one relationship with the patients, but also needs to be grouped based on patients' event times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78b23d8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3783140394.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [29]\u001b[0;36m\u001b[0m\n\u001b[0;31m    def L_z(z: np.array, K=1: int):\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "K = 1 #Number of institutions\n",
    "dt = num_unique_times # Number of unique event times\n",
    "\n",
    "\n",
    "def L_z(z: np.array, K: int, gamma_old:np.array, sigma, rho):\n",
    "    \n",
    "    Rt = group_samples_at_risk(z)\n",
    "    \n",
    "    component1 = L_z_component1(z, Rt)\n",
    "    component2 = L_z_component2(z, K, sigma, gamma_old, rho)\n",
    "    \n",
    "    return component1 + component2\n",
    "        \n",
    "def L_z_component1(z, Rt):\n",
    "    result = 0\n",
    "    for t, group in z_samples_at_risk.items()\n",
    "        result += dt * (K * np.exp(group)).sum()\n",
    "    \n",
    "    return result\n",
    "        \n",
    "def L_z_component2(z, K, sigma, gamma_old, rho):\n",
    "    # TODO: check why we use gamma_old\n",
    "    element_wise = np.square(z)/2 - sigma + (gamm_old/rho) * z\n",
    "    return K * rho * element_wise.sum()\n",
    "    \n",
    "\n",
    "# Test if the output type is as expected (should be a scalar)\n",
    "\n",
    "def test_lz_outputs_scalar():\n",
    "    # Data with two samples\n",
    "    columns = ['lenfol', 'z', 'gamma', 'sigma', 'rho']\n",
    "    data = np.arange((2, len(columns)))\n",
    "    \n",
    "    samples = pd.DataFrame(data=data, columns=columns)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e1119ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 21, 27])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(np.array([1,2,3]).transpose(), np.array([[2,3,4], [2,3,4], [3,4,5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70c37bed",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1779160323.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [35]\u001b[0;36m\u001b[0m\n\u001b[0;31m    def (a:np.array):\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def (a:np.array):\n",
    "    return a * a.transpose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40390d",
   "metadata": {},
   "source": [
    "## Risks\n",
    "### Differential privacy-ish\n",
    "If the difference between $D_t$ and $D_{t+1}$, and similarly, the difference between $R_t$ and $R_{t+1}$ is too small, there is a great risk of data leakage. This needs to be addressed.\n",
    "\n",
    "### \"Gradient\" leakage\n",
    "The central server computes a variable $\\boldsymbol{\\overline{z}}$ which is a vector where every element corresponds to an individual patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6c2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
