{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ccea1e-f04d-4d19-94c1-a09e38a61433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sksurv.datasets import load_whas500\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29c9a2a-5455-485b-ba46-149de1c256ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_whas500()\n",
    "X = X.astype(float)\n",
    "# Combining features and events is easier to work with for now\n",
    "combined = pd.concat([X, pd.DataFrame(y)], axis=1)\n",
    "combined['lenfol'] = combined['lenfol'].astype(int)\n",
    "TARGET_COLUMNS = ['fstat', 'lenfol']\n",
    "\n",
    "\n",
    "\n",
    "right_censored = np.array([el[0] for el in y])\n",
    "event_times = np.array([el[1] for el in y]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ebe64-4ae5-4aa8-90ed-d1c17768fd8a",
   "metadata": {},
   "source": [
    "# Constructing the components\n",
    "In order to solve equation 8we need to filter and group the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9f0ed0-eeb1-4862-8fb3-6634bfdce6a7",
   "metadata": {},
   "source": [
    "## $D_t$\n",
    "We need to group the records on event time, ignore the right-censored records\n",
    "\n",
    "Then we get $D_t$ for every $t$ from $t=1$ to $T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ecec6bd-e7bd-4e97-b3e1-02ffacf0a002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">afb</th>\n",
       "      <th colspan=\"2\" halign=\"left\">age</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sho</th>\n",
       "      <th colspan=\"8\" halign=\"left\">sysbp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lenfol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.00</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.00</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>132.333333</td>\n",
       "      <td>18.610033</td>\n",
       "      <td>115.0</td>\n",
       "      <td>122.50</td>\n",
       "      <td>130.0</td>\n",
       "      <td>141.00</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.00</td>\n",
       "      <td>164.0</td>\n",
       "      <td>164.00</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>22.627417</td>\n",
       "      <td>179.0</td>\n",
       "      <td>187.00</td>\n",
       "      <td>195.0</td>\n",
       "      <td>203.00</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>141.500000</td>\n",
       "      <td>34.648232</td>\n",
       "      <td>117.0</td>\n",
       "      <td>129.25</td>\n",
       "      <td>141.5</td>\n",
       "      <td>153.75</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         afb                                      age             ...  sho  \\\n",
       "       count mean  std  min  25%  50%  75%  max count       mean  ...  75%   \n",
       "lenfol                                                            ...        \n",
       "368      1.0  0.0  NaN  0.0  0.0  0.0  0.0  0.0   1.0  46.000000  ...  0.0   \n",
       "371      3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   3.0  73.333333  ...  0.0   \n",
       "373      1.0  0.0  NaN  0.0  0.0  0.0  0.0  0.0   1.0  65.000000  ...  0.0   \n",
       "376      2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   2.0  60.000000  ...  0.0   \n",
       "386      2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   2.0  55.500000  ...  0.0   \n",
       "\n",
       "            sysbp                                                              \n",
       "        max count        mean        std    min     25%    50%     75%    max  \n",
       "lenfol                                                                         \n",
       "368     0.0   1.0  149.000000        NaN  149.0  149.00  149.0  149.00  149.0  \n",
       "371     0.0   3.0  132.333333  18.610033  115.0  122.50  130.0  141.00  152.0  \n",
       "373     0.0   1.0  164.000000        NaN  164.0  164.00  164.0  164.00  164.0  \n",
       "376     0.0   2.0  195.000000  22.627417  179.0  187.00  195.0  203.00  211.0  \n",
       "386     0.0   2.0  141.500000  34.648232  117.0  129.25  141.5  153.75  166.0  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First ignore all right-censored records\n",
    "dt = combined[~combined['fstat']]\n",
    "\n",
    "# We don't need the censor column anymore\n",
    "dt = dt.drop(['fstat'], axis=1)\n",
    "\n",
    "# Group on event time\n",
    "dt = dt.groupby('lenfol')\n",
    "\n",
    "dt.describe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cde6a8",
   "metadata": {},
   "source": [
    "## $R_t$\n",
    "$R_t$ denotes the set of samples at risk of the event at time $t$. This includes samples with an event at time t, the samples with an event later than time t, and right-censored samples.\n",
    "\n",
    "*I __think__ that I can treat right-censored samples the same as regular samples for this set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e49862",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = combined\n",
    "\n",
    "# I will create a bucket per unique lenfol and create a new dataframe per bucket with all samples at risk at that time\n",
    "unique_times = rt['lenfol'].unique()\n",
    "\n",
    "num_unique_times = len(unique_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b84ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.arange(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a12ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_samples_at_risk(event_times: np.array):\n",
    "    \"\"\"\n",
    "    Groups the indices of samples on whether they are at risk at a certain time.\n",
    "    \n",
    "    A sample is at risk at a certain time when its event time is greater or equal that time.\n",
    "    \"\"\"\n",
    "    unique_times = np.unique(event_times)\n",
    "    \n",
    "    grouped = {}\n",
    "    \n",
    "    for t in unique_times:\n",
    "        grouped[t] = np.argwhere(event_times>= t)\n",
    "    \n",
    "    return grouped\n",
    "\n",
    "Rt = group_samples_at_risk(event_times)\n",
    "\n",
    "\n",
    "def test_group_samples_at_risk_numbers_descend():\n",
    "    # Testing if the resulting list descends in numbers\n",
    "    previous_length = len(event_times) + 1\n",
    "\n",
    "    for t in sorted(Rt.keys()):\n",
    "        length = len(Rt[t])\n",
    "\n",
    "        assert length < previous_length\n",
    "\n",
    "        previous_length = length\n",
    "        \n",
    "test_group_samples_at_risk_numbers_descend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d80d8b-3758-4e6e-aac8-1d55e5b07d36",
   "metadata": {},
   "source": [
    "## $\\sum \\limits_{t=1}^{T} \\sum \\limits_{n \\in D_t} \\mathbf{x}_{nk}$\n",
    "\n",
    "$D_t$ is the list of indices with an observed event at time $t$.\n",
    "\n",
    "This part seems to be constant throughout the optimization?\n",
    "\n",
    "I think this is just a big fat sum of all the patients' covariants. It will stay constant per institution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4cebf30-02e7-4446-9428-27ca83f5cb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.800000e+01, 3.492300e+04, 1.100000e+01, 1.330689e+04,\n",
       "       1.550000e+02, 3.750000e+02, 3.913300e+04, 2.000000e+02,\n",
       "       4.350900e+04, 3.058000e+03, 1.710000e+02, 1.530000e+02,\n",
       "       2.200000e+01, 7.235200e+04])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariates_sum = combined.drop(TARGET_COLUMNS, axis=1).values.sum(axis=0)\n",
    "\n",
    "covariates_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f3b6248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,  83.,   0., ...,   0.,   0., 152.],\n",
       "       [  0.,  49.,   0., ...,   1.,   0., 120.],\n",
       "       [  0.,  70.,   0., ...,   1.,   0., 147.],\n",
       "       ...,\n",
       "       [  1.,  57.,   0., ...,   0.,   0., 120.],\n",
       "       [  0.,  67.,   0., ...,   1.,   0., 112.],\n",
       "       [  0.,  98.,   0., ...,   1.,   0., 160.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Covariates\n",
    "X.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87705ee-c95f-48a3-ade6-4ce66d9c8e6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Local update\n",
    "\n",
    "$ \\beta_k^{(p)} = \\bigg[ \\rho \\sum \\limits_{n=1}^{N} \\mathbf{x}_{nk}\\mathbf{x}_{nk}^T\\bigg]^{-1} \\cdot \\bigg[\\sum \\limits_{n=1}^N  (\\rho z_{nk}^{(p-1)} - \\gamma_{nk}^{p-1}) \\mathbf{x}_{nk} + \\sum \\limits_{t=1}^T \\sum \\limits_{n \\in D_t} \\mathbf{x}_{nk}\\bigg] $\n",
    "\n",
    "There are two parts to this computation that seem to be constant over iterations:\n",
    "1. $\\rho \\sum \\limits_{n=1}^{N} \\mathbf{x}_{nk}\\mathbf{x}_{nk}^T$\n",
    "2. $\\sum \\limits_{t=1}^T \\sum \\limits_{n \\in D_t} \\mathbf{x}_{nk}$\n",
    "\n",
    "Number 2. is also the part where we need to apply the scalar product protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2d53fe3-ef61-4dca-958a-0c5428255bc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (514,) (2,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     updated \u001b[38;5;241m=\u001b[39m local_update(covariates, z, gamma, rho, multiplied_cov, summed_cov)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m updated\u001b[38;5;241m.\u001b[39mshape() \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m1\u001b[39m,)\n\u001b[0;32m---> 45\u001b[0m \u001b[43mtest_local_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m np\u001b[38;5;241m.\u001b[39marange()\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mtest_local_update\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m multiplied_cov \u001b[38;5;241m=\u001b[39m multiply_covariates(covariates)\n\u001b[1;32m     39\u001b[0m summed_cov \u001b[38;5;241m=\u001b[39m sum_covariates(covariates)\n\u001b[0;32m---> 41\u001b[0m updated \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcovariates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiplied_cov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummed_cov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m updated\u001b[38;5;241m.\u001b[39mshape() \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m1\u001b[39m,)\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mlocal_update\u001b[0;34m(covariates, z, gamma, rho, multiplied_covariates, covariates_sum)\u001b[0m\n\u001b[1;32m     23\u001b[0m pz \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmultiply(rho, z)\n\u001b[1;32m     25\u001b[0m second_component \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmultiply(pz \u001b[38;5;241m-\u001b[39m gamma, covariates) \u001b[38;5;241m+\u001b[39m covariates_sum    \n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfirst_component\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msecond_component\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/verticox-HtUDtOxM-py3.8/lib/python3.8/site-packages/pandas/core/ops/common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     68\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/verticox-HtUDtOxM-py3.8/lib/python3.8/site-packages/pandas/core/arraylike.py:116\u001b[0m, in \u001b[0;36mOpsMixin.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__mul__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/verticox-HtUDtOxM-py3.8/lib/python3.8/site-packages/pandas/core/series.py:5639\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m   5638\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_SERIES(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[0;32m-> 5639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/verticox-HtUDtOxM-py3.8/lib/python3.8/site-packages/pandas/core/base.py:1295\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1292\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1295\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/verticox-HtUDtOxM-py3.8/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:222\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[0;32m--> 222\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/verticox-HtUDtOxM-py3.8/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:163\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    160\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/verticox-HtUDtOxM-py3.8/lib/python3.8/site-packages/pandas/core/computation/expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/verticox-HtUDtOxM-py3.8/lib/python3.8/site-packages/pandas/core/computation/expressions.py:128\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    125\u001b[0m     _store_test_result(result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_evaluate_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/verticox-HtUDtOxM-py3.8/lib/python3.8/site-packages/pandas/core/computation/expressions.py:69\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[1;32m     68\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (514,) (2,2) "
     ]
    }
   ],
   "source": [
    "# Local update\n",
    "RHO = 0.25\n",
    "\n",
    "# Parts that stay constant over iterations\n",
    "# Square all covariates and sum them together\n",
    "# The formula says for every patient, x needs to be multiplied by itself.\n",
    "# Squaring all covariates with themselves comes down to the same thing since x_nk is supposed to\n",
    "# be one-dimensional\n",
    "multiplied_covariates = (X* X.transpose()).sum(axis=0)\n",
    "covariates_summed = combined.drop(TARGET_COLUMNS, axis=1).values.sum(axis=0)\n",
    "\n",
    "def sum_covariates(covariates: np.array):\n",
    "    return np.sum(covariates, axis=0)\n",
    "    \n",
    "def multiply_covariates(covariates: np.array):\n",
    "    return (X* X.transpose()).sum(axis=0)\n",
    "\n",
    "def local_update(covariates:np.array, z:np.array, gamma:np.array, rho,\n",
    "                 multiplied_covariates, covariates_sum):\n",
    "    \n",
    "    first_component = 1/(rho * multiplied_covariates)\n",
    "    \n",
    "    pz = np.multiply(rho, z)\n",
    "    \n",
    "    second_component = np.multiply(pz - gamma, covariates) + covariates_sum    \n",
    "    \n",
    "    return first_component * second_component\n",
    "\n",
    "def test_sum_covariates_returns_scalar():\n",
    "    num_patients = 2\n",
    "    num_features = 2\n",
    "    \n",
    "    covariates = np.arange(num_patients * num_features).reshape((num_patients, num_features))\n",
    "    \n",
    "    result = sum_covariates(covariates)\n",
    "    assert np.isscalar(result)\n",
    "\n",
    "\n",
    "def test_local_update():\n",
    "    num_patients = 2\n",
    "    num_features = 2\n",
    "    \n",
    "    rho=1\n",
    "    covariates = np.arange(num_patients*num_features).reshape((num_patients, num_features))\n",
    "    z = np.arange(num_patients)\n",
    "    gamma = np.arange(num_patients)\n",
    "    multiplied_cov = multiply_covariates(covariates)\n",
    "    summed_cov = sum_covariates(covariates)\n",
    "    \n",
    "    updated = local_update(covariates, z, gamma, rho, multiplied_cov, summed_cov)\n",
    "    \n",
    "    assert updated.shape() == (1,)\n",
    "\n",
    "test_local_update()\n",
    "np.arange()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee47d801",
   "metadata": {},
   "source": [
    "## Server update\n",
    "- Server computes:\n",
    "    - $\\overline{\\sigma}_n^{(p)} = \\sum \\limits_{k=1}^K \\sigma_{nk}^{(p)}/K $\n",
    "    - $\\overline{\\gamma}_{n}^{(p)} = \\sum \\limits_{k=1}^K \\gamma_{nk}^{(p)}/K $\n",
    "- Server computes $\\overline{z}^{(p)}$ by applying Newton-Raphson to:\n",
    "$ \\sum_{t=1}^T \\left[d_t log \\sum \\limits_{j \\in R_t} exp(K \\overline{z}_j) \\right] + K \\rho \\sum \\limits_{n=1}^N \\left[ \\frac{\\overline{z}_n^2}{2} - \n",
    "\\left( \\overline{\\sigma}_n^{(p)} + \\frac{\\overline{\\gamma}_n^{(p-1)}}{\\rho} \\right) \\overline{z}_n \\right]    $\n",
    "\n",
    "### Person-level auxiliary variables\n",
    "For the update the server makes use of the auxiliary variables $\\overline{\\sigma}$ and $\\overline{\\gamma}$. The elements of these vectors have a one-on-one relationship with the patients.\n",
    "\n",
    "Moreover, the server tries to find a variable $\\overline{z}$ which not only has a one-on-one relationship with the patients, but also needs to be grouped based on patients' event times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78b23d8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3783140394.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [29]\u001b[0;36m\u001b[0m\n\u001b[0;31m    def L_z(z: np.array, K=1: int):\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "K = 1 #Number of institutions\n",
    "dt = num_unique_times # Number of unique event times\n",
    "\n",
    "\n",
    "def L_z(z: np.array, K: int, gamma_old:np.array, sigma, rho):\n",
    "    \n",
    "    Rt = group_samples_at_risk(z)\n",
    "    \n",
    "    component1 = L_z_component1(z, Rt)\n",
    "    component2 = L_z_component2(z, K, sigma, gamma_old, rho)\n",
    "    \n",
    "    return component1 + component2\n",
    "        \n",
    "def L_z_component1(z, Rt):\n",
    "    result = 0\n",
    "    for t, group in z_samples_at_risk.items()\n",
    "        result += dt * (K * np.exp(group)).sum()\n",
    "    \n",
    "    return result\n",
    "        \n",
    "def L_z_component2(z, K, sigma, gamma_old, rho):\n",
    "    # TODO: check why we use gamma_old\n",
    "    element_wise = np.square(z)/2 - sigma + (gamm_old/rho) * z\n",
    "    return K * rho * element_wise.sum()\n",
    "    \n",
    "\n",
    "# Test if the output type is as expected (should be a scalar)\n",
    "\n",
    "def test_lz_outputs_scalar():\n",
    "    # Data with two samples\n",
    "    columns = ['lenfol', 'z', 'gamma', 'sigma', 'rho']\n",
    "    data = np.arange((2, len(columns)))\n",
    "    \n",
    "    samples = pd.DataFrame(data=data, columns=columns)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1119ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 10, 15])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.array([1,2,3]) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70c37bed",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1779160323.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [35]\u001b[0;36m\u001b[0m\n\u001b[0;31m    def (a:np.array):\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def (a:np.array):\n",
    "    return a * a.transpose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40390d",
   "metadata": {},
   "source": [
    "## Risks\n",
    "### Differential privacy-ish\n",
    "If the difference between $D_t$ and $D_{t+1}$, and similarly, the difference between $R_t$ and $R_{t+1}$ is too small, there is a great risk of data leakage. This needs to be addressed.\n",
    "\n",
    "### \"Gradient\" leakage\n",
    "The central server computes a variable $\\boldsymbol{\\overline{z}}$ which is a vector where every element corresponds to an individual patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6c2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
